{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18gv2sb_D06j",
        "outputId": "e8d9291a-6654-48ab-a3e9-9f102ab7d07f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "[1, 2000] loss: 2.163\n",
            "[1, 4000] loss: 1.741\n",
            "[1, 6000] loss: 1.559\n",
            "[1, 8000] loss: 1.426\n",
            "[1, 10000] loss: 1.355\n",
            "[1, 12000] loss: 1.293\n",
            "[2, 2000] loss: 1.186\n",
            "[2, 4000] loss: 1.162\n",
            "[2, 6000] loss: 1.117\n",
            "[2, 8000] loss: 1.108\n",
            "[2, 10000] loss: 1.057\n",
            "[2, 12000] loss: 1.060\n",
            "[3, 2000] loss: 0.949\n",
            "[3, 4000] loss: 0.940\n",
            "[3, 6000] loss: 0.923\n",
            "[3, 8000] loss: 0.915\n",
            "[3, 10000] loss: 0.919\n",
            "[3, 12000] loss: 0.915\n",
            "[4, 2000] loss: 0.779\n",
            "[4, 4000] loss: 0.815\n",
            "[4, 6000] loss: 0.812\n",
            "[4, 8000] loss: 0.811\n",
            "[4, 10000] loss: 0.811\n",
            "[4, 12000] loss: 0.824\n",
            "[5, 2000] loss: 0.670\n",
            "[5, 4000] loss: 0.699\n",
            "[5, 6000] loss: 0.706\n",
            "[5, 8000] loss: 0.688\n",
            "[5, 10000] loss: 0.717\n",
            "[5, 12000] loss: 0.733\n",
            "[6, 2000] loss: 0.587\n",
            "[6, 4000] loss: 0.603\n",
            "[6, 6000] loss: 0.603\n",
            "[6, 8000] loss: 0.621\n",
            "[6, 10000] loss: 0.641\n",
            "[6, 12000] loss: 0.618\n",
            "[7, 2000] loss: 0.482\n",
            "[7, 4000] loss: 0.504\n",
            "[7, 6000] loss: 0.534\n",
            "[7, 8000] loss: 0.541\n",
            "[7, 10000] loss: 0.576\n",
            "[7, 12000] loss: 0.564\n",
            "[8, 2000] loss: 0.397\n",
            "[8, 4000] loss: 0.444\n",
            "[8, 6000] loss: 0.471\n",
            "[8, 8000] loss: 0.488\n",
            "[8, 10000] loss: 0.498\n",
            "[8, 12000] loss: 0.507\n",
            "[9, 2000] loss: 0.337\n",
            "[9, 4000] loss: 0.372\n",
            "[9, 6000] loss: 0.412\n",
            "[9, 8000] loss: 0.424\n",
            "[9, 10000] loss: 0.439\n",
            "[9, 12000] loss: 0.462\n",
            "[10, 2000] loss: 0.299\n",
            "[10, 4000] loss: 0.333\n",
            "[10, 6000] loss: 0.362\n",
            "[10, 8000] loss: 0.366\n",
            "[10, 10000] loss: 0.390\n",
            "[10, 12000] loss: 0.425\n",
            "Finished Training\n",
            "Accuracy of the network on the 10000 test images: 67 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn.functional as F  # Import F for functional operations\n",
        "\n",
        "# Define a simple CNN model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
        "        self.fc1 = nn.Linear(self._get_conv_output((3, 32, 32)), 120)  # Updated\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "\n",
        "    def _get_conv_output(self, shape):\n",
        "        # Create a dummy input to pass through the network\n",
        "        with torch.no_grad():\n",
        "            return self._forward(torch.autograd.Variable(torch.ones(1, *shape))).view(1, -1).size(1)\n",
        "\n",
        "    def _forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self._forward(x)\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor dynamically\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load and preprocess data\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert images to tensors\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize images\n",
        "])\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True)\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False)\n",
        "\n",
        "# Initialize and train the model\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # Use GPU if available\n",
        "model = SimpleCNN().to(device)  # Move model to device\n",
        "criterion = nn.CrossEntropyLoss()  # Define loss function\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)  # Define optimizer\n",
        "\n",
        "for epoch in range(10):  # Loop over the dataset multiple times\n",
        "    running_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)  # Move data to device\n",
        "\n",
        "        optimizer.zero_grad()  # Zero the gradients\n",
        "\n",
        "        outputs = model(inputs)  # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Compute loss\n",
        "        loss.backward()  # Backward pass\n",
        "        optimizer.step()  # Update weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # Print every 2000 mini-batches\n",
        "            print(f'[{epoch + 1}, {i + 1}] loss: {running_loss / 2000:.3f}')\n",
        "            running_loss = 0.0\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Evaluate the model\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        outputs = model(images.to(device))  # Forward pass\n",
        "        _, predicted = torch.max(outputs.data, 1)  # Get predicted labels\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted.cpu() == labels).sum().item()  # Count correct predictions\n",
        "\n",
        "print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lIEx6zdHD181"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}